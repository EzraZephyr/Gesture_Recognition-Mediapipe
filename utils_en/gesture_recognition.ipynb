{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-07T05:10:50.912839Z",
     "start_time": "2024-09-07T05:10:44.776680Z"
    }
   },
   "source": [
    "import cv2\n",
    "import time\n",
    "import mediapipe\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from filterpy.kalman import KalmanFilter"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T05:10:50.928940Z",
     "start_time": "2024-09-07T05:10:50.913896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gesture_locked = {'Left':False,'Right':False}\n",
    "gesture_start_time = {'Left':0,'Right':0}\n",
    "buffer_start_time = {'Left':0,'Right':0}\n",
    "start_drag_time = {'Left':0,'Right':0}\n",
    "dragging = {'Left':False,'Right':False}\n",
    "drag_point = {'Left':(0, 0),'Right':(0, 0)}\n",
    "buffer_duration = {'Left':0.25,'Right':0.25}\n",
    "is_index_finger_up = {'Left':False,'Right':False}\n",
    "index_finger_second = {'Left':0,'Right':0}\n",
    "index_finger_tip = {'Left':0,'Right':0}\n",
    "trajectory = {'Left':[],'Right':[]}\n",
    "square_queue = deque()\n",
    "wait_time = 1.5\n",
    "kalman_wait_time = 0.5\n",
    "wait_box = 2\n",
    "rect_draw_time = {'Left':0,'Right':0}\n",
    "last_drawn_box = {'Left':None,'Right':None}\n",
    "elapsed_time = {'Left':0,'Right':0}"
   ],
   "id": "40aada17ccd31fe",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T05:10:55.708038Z",
     "start_time": "2024-09-07T05:10:55.691926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clear_hand_states(detected_hand='Both'):\n",
    "    global gesture_locked, gesture_start_time, buffer_start_time, dragging, drag_point, buffer_duration, is_index_finger_up, trajectory, wait_time, kalman_wait_time, start_drag_time, rect_draw_time, last_drawn_box, wait_box, elapsed_time\n",
    "\n",
    "    hands_to_clear = {'Left', 'Right'}\n",
    "    if detected_hand == 'Both':\n",
    "        hands_to_clear = hands_to_clear\n",
    "    else:\n",
    "        hands_to_clear -= {detected_hand}\n",
    "        # Reverse check for left and right hands\n",
    "\n",
    "    for h in hands_to_clear:\n",
    "        gesture_locked[h] = False\n",
    "        gesture_start_time[h] = 0\n",
    "        buffer_start_time[h] = 0\n",
    "        dragging[h] = False\n",
    "        drag_point[h] = (0, 0)\n",
    "        buffer_duration[h] = 0.25\n",
    "        is_index_finger_up[h] = False\n",
    "        trajectory[h].clear()\n",
    "        start_drag_time[h] = 0\n",
    "        rect_draw_time[h] = 0\n",
    "        last_drawn_box[h] = None\n",
    "        elapsed_time[h] = 0\n",
    "        # Clear states for hands that are not detected"
   ],
   "id": "2ee9323bb1c25cc0",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T05:10:56.547939Z",
     "start_time": "2024-09-07T05:10:56.532265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "kalman_filters = {\n",
    "    'Left': KalmanFilter(dim_x=4, dim_z=2),\n",
    "    'Right': KalmanFilter(dim_x=4, dim_z=2)\n",
    "}\n",
    "\n",
    "for key in kalman_filters:\n",
    "    kalman_filters[key].x = np.array([0., 0., 0., 0.])\n",
    "    kalman_filters[key].F = np.array([[1, 0, 1, 0],\n",
    "                                      [0, 1, 0, 1],\n",
    "                                      [0, 0, 1, 0],\n",
    "                                      [0, 0, 0, 1]])\n",
    "    # State transition matrix\n",
    "    kalman_filters[key].H = np.array([[1, 0, 0, 0],\n",
    "                                      [0, 1, 0, 0]])\n",
    "    # Observation matrix\n",
    "    kalman_filters[key].P *= 1000.\n",
    "    kalman_filters[key].R = 3\n",
    "    kalman_filters[key].Q = np.eye(4) * 0.01\n",
    "\n",
    "def kalman_filter_point(hand_label, x, y):\n",
    "    kf = kalman_filters[hand_label]\n",
    "    kf.predict()\n",
    "    kf.update([x, y])\n",
    "    # Update state\n",
    "    return (kf.x[0], kf.x[1])\n",
    "\n",
    "def reset_kalman_filter(hand_label, x, y):\n",
    "    kf = kalman_filters[hand_label]\n",
    "    kf.x = np.array([x, y, 0., 0.])\n",
    "    kf.P *= 1000.\n",
    "    # Reset"
   ],
   "id": "96cf431d2562e7d",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T05:10:57.253008Z",
     "start_time": "2024-09-07T05:10:57.231898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mp_hands = mediapipe.solutions.hands\n",
    "\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=2,\n",
    "    # One hand is more stable\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "mp_drawing = mediapipe.solutions.drawing_utils\n",
    "clear_hand_states()"
   ],
   "id": "edc274b7ed495122",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T05:10:58.920644Z",
     "start_time": "2024-09-07T05:10:58.881367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_image(image):\n",
    "\n",
    "    start_time = time.time()\n",
    "    height, width = image.shape[:2]\n",
    "    image = cv2.flip(image, 1)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # Preprocess the input frame\n",
    "\n",
    "    results = hands.process(image)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        # If hands are detected\n",
    "\n",
    "        handness_str = ''\n",
    "        index_finger_tip_str = ''\n",
    "\n",
    "        if len(results.multi_hand_landmarks) == 1:\n",
    "            clear_hand_states(detected_hand=results.multi_handedness[0].classification[0].label)\n",
    "            # If only one hand is detected, clear the data of the other hand to avoid conflicts that could cause instability.\n",
    "\n",
    "        for hand_idx in range(len(results.multi_hand_landmarks)):\n",
    "\n",
    "            hand_21 = results.multi_hand_landmarks[hand_idx]\n",
    "            mp_drawing.draw_landmarks(image, hand_21, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            temp_handness = results.multi_handedness[hand_idx].classification[0].label\n",
    "            handness_str += '{}:{}, '.format(hand_idx, temp_handness)\n",
    "            is_index_finger_up[temp_handness] = False\n",
    "            # Set to False first to prevent incorrect updates to raised when lowered\n",
    "\n",
    "            cz0 = hand_21.landmark[0].z\n",
    "            index_finger_second[temp_handness] = hand_21.landmark[7]\n",
    "            index_finger_tip[temp_handness] = hand_21.landmark[8]\n",
    "            # Index fingertip and first joint\n",
    "\n",
    "            index_x, index_y = int(index_finger_tip[temp_handness].x * width), int(index_finger_tip[temp_handness].y * height)\n",
    "\n",
    "            if all(index_finger_second[temp_handness].y < hand_21.landmark[i].y for i in range(21) if i not in [7, 8]) and index_finger_tip[temp_handness].y < index_finger_second[temp_handness].y:\n",
    "                is_index_finger_up[temp_handness] = True\n",
    "                # If the fingertip and second joint are higher than all other keypoints on the hand, consider it as a \"pointing\" gesture. \n",
    "\n",
    "            if is_index_finger_up[temp_handness]:\n",
    "                if not gesture_locked[temp_handness]:\n",
    "                    if gesture_start_time[temp_handness] == 0:\n",
    "                        gesture_start_time[temp_handness] = time.time()\n",
    "                        # Record the time when the index finger is raised\n",
    "                    elif time.time() - gesture_start_time[temp_handness] > wait_time:\n",
    "                        dragging[temp_handness] = True\n",
    "                        gesture_locked[temp_handness] = True\n",
    "                        drag_point[temp_handness] = (index_x, index_y)\n",
    "                        # If the index finger is raised for longer than the set wait time, it is considered a \"pointing\" gesture.\n",
    "                    buffer_start_time[temp_handness] = 0\n",
    "                    # Refresh the buffer time whenever the index finger is raised\n",
    "            else:\n",
    "                if buffer_start_time[temp_handness] == 0:\n",
    "                    buffer_start_time[temp_handness] = time.time()\n",
    "                elif time.time() - buffer_start_time[temp_handness] > buffer_duration[temp_handness]:\n",
    "                    gesture_start_time[temp_handness] = 0\n",
    "                    gesture_locked[temp_handness] = False\n",
    "                    dragging[temp_handness] = False\n",
    "                    # If the buffer time exceeds the set limit, it indicates the end of the pointing gesture.\n",
    "                    # This prevents incorrect clearing of the pointing gesture due to recognition errors in a single frame.\n",
    "\n",
    "            if dragging[temp_handness]:\n",
    "\n",
    "                if start_drag_time[temp_handness] == 0:\n",
    "                    start_drag_time[temp_handness] = time.time()\n",
    "                    reset_kalman_filter(temp_handness, index_x, index_y)\n",
    "                    # Initialize the filter whenever a line is drawn\n",
    "\n",
    "                smooth_x, smooth_y = kalman_filter_point(temp_handness, index_x, index_y)\n",
    "                drag_point[temp_handness] = (index_x, index_y)\n",
    "                index_finger_radius = max(int(10 * (1 + (cz0 - index_finger_tip[temp_handness].z) * 5)), 0)\n",
    "                cv2.circle(image, drag_point[temp_handness], index_finger_radius, (0, 0, 255), -1)\n",
    "                # Create a circle based on the depth distance from the wrist root\n",
    "                # This is used to show that the pointing gesture has started\n",
    "                # The corresponding depth points below are scaled directly\n",
    "                drag_point_smooth = (smooth_x, smooth_y)\n",
    "\n",
    "                if time.time() - start_drag_time[temp_handness] > kalman_wait_time:\n",
    "                    trajectory[temp_handness].append(drag_point_smooth)\n",
    "                    # The Kalman filter can be very unstable when initialized, with significant noise in the first few frames\n",
    "                    # Wait until the first few frames have run before adding the coordinates to the trajectory list.\n",
    "            else:\n",
    "                if len(trajectory[temp_handness]) > 4:\n",
    "                    contour = np.array(trajectory[temp_handness], dtype=np.int32)\n",
    "                    rect = cv2.minAreaRect(contour)\n",
    "                    box = cv2.boxPoints(rect)\n",
    "                    box = np.int0(box)\n",
    "                    rect_draw_time[temp_handness] = time.time()\n",
    "                    last_drawn_box[temp_handness] = box\n",
    "                    # If the pointing gesture ends and there are at least four points in the trajectory list,\n",
    "                    # Use the minimum bounding box to adjust the irregular drawing to a rectangle.\n",
    "\n",
    "                start_drag_time[temp_handness] = 0\n",
    "                trajectory[temp_handness].clear()\n",
    "\n",
    "            for i in range(1, len(trajectory[temp_handness])):\n",
    "\n",
    "                pt1 = (int(trajectory[temp_handness][i-1][0]), int(trajectory[temp_handness][i-1][1]))\n",
    "                pt2 = (int(trajectory[temp_handness][i][0]), int(trajectory[temp_handness][i][1]))\n",
    "                cv2.line(image, pt1, pt2, (0, 0, 255), 2)\n",
    "                # Draw lines connecting trajectory points\n",
    "\n",
    "            if last_drawn_box[temp_handness] is not None:\n",
    "                elapsed_time[temp_handness] = time.time() - rect_draw_time[temp_handness]\n",
    "\n",
    "                if elapsed_time[temp_handness] < wait_box:\n",
    "                    cv2.drawContours(image, [last_drawn_box[temp_handness]], 0, (0, 255, 0), 2)\n",
    "                    # Keep the rectangle visible for a while, otherwise, it's too fast to observe.\n",
    "\n",
    "                elif elapsed_time[temp_handness] >= wait_box - 0.1:\n",
    "\n",
    "                    box = last_drawn_box[temp_handness]\n",
    "                    x_min = max(0, min(box[:, 0]))\n",
    "                    y_min = max(0, min(box[:, 1]))\n",
    "                    x_max = min(image.shape[1], max(box[:, 0]))\n",
    "                    y_max = min(image.shape[0], max(box[:, 1]))\n",
    "                    cropped_image = image[y_min:y_max, x_min:x_max]\n",
    "                    filename = f\"../image/cropped_{temp_handness}_{int(time.time())}.jpg\"\n",
    "                    cv2.imwrite(filename, cropped_image)\n",
    "                    last_drawn_box[temp_handness] = None\n",
    "                # The drawn image cannot be cropped immediately, as it might wrongly crop the hand into it.\n",
    "                # Wait a while to give the hand time to move away before extracting the rectangle from this frame.\n",
    "\n",
    "            for i in range(21):\n",
    "\n",
    "                cx = int(hand_21.landmark[i].x * width)\n",
    "                cy = int(hand_21.landmark[i].y * height)\n",
    "                cz = hand_21.landmark[i].z\n",
    "                depth_z = cz0 - cz\n",
    "                radius = max(int(6 * (1 + depth_z * 5)), 0)\n",
    "\n",
    "                if i == 0:\n",
    "                    image = cv2.circle(image, (cx, cy), radius, (255, 255, 0), thickness=-1)\n",
    "                if i == 8:\n",
    "                    image = cv2.circle(image, (cx, cy), radius, (255, 165, 0), thickness=-1)\n",
    "                    index_finger_tip_str += '{}:{:.2f}, '.format(hand_idx, depth_z)\n",
    "                if i in [1, 5, 9, 13, 17]:\n",
    "                    image = cv2.circle(image, (cx, cy), radius,  (0, 0, 255), thickness=-1)\n",
    "                if i in [2, 6, 10, 14, 18]:\n",
    "                    image = cv2.circle(image, (cx, cy), radius,  (75, 0, 130), thickness=-1)\n",
    "                if i in [3, 7, 11, 15, 19]:\n",
    "                    image = cv2.circle(image, (cx, cy), radius, (238, 130, 238), thickness=-1)\n",
    "                if i in [4, 12, 16, 20]:\n",
    "                    image = cv2.circle(image, (cx, cy), radius, (0, 255, 255), thickness=-1)\n",
    "                # Extract each keypoint, assign corresponding colors, and set depth based on the wrist root.\n",
    "\n",
    "        scaler = 1\n",
    "        image = cv2.putText(image, handness_str, (25 * scaler, 100 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (0, 0, 255), 2)\n",
    "        image = cv2.putText(image, index_finger_tip_str, (25 * scaler, 150 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (0, 0, 255), 2,)\n",
    "\n",
    "        spend_time = time.time() - start_time\n",
    "        if spend_time > 0:\n",
    "            FPS = 1.0 / spend_time\n",
    "        else:\n",
    "            FPS = 0\n",
    "\n",
    "        image = cv2.putText(image, 'FPS ' + str(int(FPS)), (25 * scaler, 50 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (0, 0, 255), 2,)\n",
    "        # Display FPS, detected hands, and the depth value of the index fingertip relative to the wrist root.\n",
    "\n",
    "    else:\n",
    "        clear_hand_states()\n",
    "        # If no hands are detected, clear all information.\n",
    "\n",
    "    return image"
   ],
   "id": "51ff809ecaf1f899",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-07T05:11:15.392765Z",
     "start_time": "2024-09-07T05:10:59.535594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "cap.open(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print(\"Camera Error\")\n",
    "        break\n",
    "\n",
    "    frame = process_image(frame)\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()  "
   ],
   "id": "b7ce23e80ed36041",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1102d2fc75310c6e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
